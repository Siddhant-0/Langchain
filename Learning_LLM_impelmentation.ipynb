{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMICkzdKFeyD0Gf2LO3eR8L",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Siddhant-0/Langchain/blob/main/Learning_LLM_impelmentation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 192,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "52SGzU0VX2nx",
        "outputId": "d56b7ac9-518f-4205-d5bd-bf18c419cff8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.25)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.58 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.65)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.8)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.45)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.11.5)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.41)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.58->langchain) (9.1.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.58->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.58->langchain) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.58->langchain) (4.14.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.18)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2025.4.26)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.2)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.58->langchain) (3.0.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.3.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install langchain-openai"
      ],
      "metadata": {
        "id": "e4MWVd_KdFWl"
      },
      "execution_count": 193,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qU \"langchain[openai]\""
      ],
      "metadata": {
        "id": "Ht_1qd8NlEBk"
      },
      "execution_count": 194,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "openai_api_key = userdata.get('OPENAI_API_KEY')\n",
        "\n",
        "langsmith_api_key=userdata.get('LANGSMITH_API_KEY')"
      ],
      "metadata": {
        "id": "UAji4VkulIOh"
      },
      "execution_count": 195,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chat_models import init_chat_model\n",
        "model = init_chat_model(\"gpt-4o-mini\", model_provider=\"openai\",api_key=openai_api_key)"
      ],
      "metadata": {
        "id": "SIp-Vzpml4pg"
      },
      "execution_count": 196,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.messages import HumanMessage, SystemMessage\n",
        "\n",
        "messages = [\n",
        "    SystemMessage(\"Translate the following from English into Italian\"),\n",
        "    HumanMessage(\"hi!\"),\n",
        "]\n",
        "\n",
        "model.invoke(messages)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rsOGPspcHb_H",
        "outputId": "43fd0bed-072b-4523-e1f8-72908613b2ec"
      },
      "execution_count": 197,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='Ciao!', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 3, 'prompt_tokens': 20, 'total_tokens': 23, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_34a54ae93c', 'id': 'chatcmpl-BiHuLZtdKnIOs8vhe986Aixvoymug', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--ef22c0d3-a4cb-4a3e-a688-6debcb6a958d-0', usage_metadata={'input_tokens': 20, 'output_tokens': 3, 'total_tokens': 23, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
            ]
          },
          "metadata": {},
          "execution_count": 197
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = model.invoke(messages)\n",
        "print(response.content)     #printing the result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TD2MtHeCHx7f",
        "outputId": "b4dc136d-d2f3-415a-e0f8-f6b68f5144c0"
      },
      "execution_count": 198,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ciao!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Same example as above (TRIAL)"
      ],
      "metadata": {
        "id": "o8ZwksLUHtoI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from langchain_core.messages import HumanMessage, SystemMessage\n",
        "\n",
        "# messages = [\n",
        "#     SystemMessage(\"Give the summary of the following message in about 20 words \"),\n",
        "#     HumanMessage(\"Nepal,[a] officially the Federal Democratic Republic of Nepal,[b] is a landlocked country in South Asia. It is mainly situated in the Himalayas, but also includes parts of the Indo-Gangetic Plain. It borders the Tibet Autonomous Region of China to the north, and India to the south, east, and west, while it is narrowly separated from Bangladesh by the Siliguri Corridor, and from Bhutan by the Indian state of Sikkim. Nepal has a diverse geography, including fertile plains, subalpine forested hills, and eight of the world's ten tallest mountains, including Mount Everest, the highest point on Earth. Kathmandu is the nation's capital and its largest city. Nepal is a multi-ethnic, multi-lingual, multi-religious, and multi-cultural state, with Nepali as the official language.\"),\n",
        "# ]\n",
        "\n",
        "# model.invoke(messages)"
      ],
      "metadata": {
        "id": "j6e-SredVw7a"
      },
      "execution_count": 199,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# response= model.invoke(messages)  # response has the result (content) along with its kwargs\n",
        "# content_result = response.content\n",
        "# # print(response)\n",
        "# print(\"Summary :  \",content_result)"
      ],
      "metadata": {
        "id": "UhW2pQzuGju3"
      },
      "execution_count": 200,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Chat models that respond to user requests\n"
      ],
      "metadata": {
        "id": "vYyq4DGkINmg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Model inputs via strings or openAI format can also be done\n",
        "\n",
        "# model.invoke(\"Hello\")\n",
        "\n",
        "#! Has three roles : ->>>>>>>>>>>>>> User, System , Assistant\n",
        "\n",
        "model.invoke([{\"role\": \"user\", \"content\": \"Hi\"}])\n",
        "\n",
        "\n",
        "\n",
        "# model.invoke([HumanMessage(\"Hello\")])"
      ],
      "metadata": {
        "id": "BkCEMVPNXBtj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce42503c-04f8-4f7e-c797-16b89ef46bd8"
      },
      "execution_count": 201,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='Hello! How can I assist you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 8, 'total_tokens': 17, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_34a54ae93c', 'id': 'chatcmpl-BiHuMkeEcG3nxBiQDcE0DdnTdizP2', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--42b1ea04-7e0e-43db-a20c-a94579b4aadb-0', usage_metadata={'input_tokens': 8, 'output_tokens': 9, 'total_tokens': 17, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
            ]
          },
          "metadata": {},
          "execution_count": 201
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "CHAT MODELS AND PROMPT TEMPLATES TO DEVELPOP A APPLICATION"
      ],
      "metadata": {
        "id": "S35mBexLkd1M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#PROMPT TEMPLATES --->\n",
        "Langchain concept that |take in raw user input and return data (a prompt) that is ready to pass into a language model."
      ],
      "metadata": {
        "id": "byFD0m1grP-1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#SYSTEM TEMPLATES\n",
        "\n",
        "* Messages were directly passed to the language model in above example.\n",
        "* The application logic takes the raw user input and transforms into a message that is raady to be passed to a language model  \n",
        "\n"
      ],
      "metadata": {
        "id": "zwUyJ1vdrjgc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#takes two user variable -----------> text and language\n",
        "\n",
        "\n",
        "#class langchain_core.prompts.chat.ChatPromptTemplate   --->>source to ChatPromptTemplate\n",
        "\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "system_template = \"Translate the following from English into {language}\"\n",
        "\n",
        "prompt_template = ChatPromptTemplate.from_messages(\n",
        "    [(\"system\", system_template), (\"user\", \"{text}\")]\n",
        ")"
      ],
      "metadata": {
        "id": "W7nGqiNlrUQl"
      },
      "execution_count": 202,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://python.langchain.com/api_reference/core/prompts/langchain_core.prompts.chat.ChatPromptTemplate.html"
      ],
      "metadata": {
        "id": "iqL8WIjbeqeE"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VBpQcW_MeoJc"
      },
      "execution_count": 202,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = prompt_template.invoke({\"language\": \"Italian\", \"text\": \"hi!\"})\n",
        "\n",
        "prompt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hOLSJO831sbG",
        "outputId": "84701b3b-399b-4399-e0e9-ea8e760c5532"
      },
      "execution_count": 203,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ChatPromptValue(messages=[SystemMessage(content='Translate the following from English into Italian', additional_kwargs={}, response_metadata={}), HumanMessage(content='hi!', additional_kwargs={}, response_metadata={})])"
            ]
          },
          "metadata": {},
          "execution_count": 203
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt.to_messages()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CCzELhUm18YO",
        "outputId": "ea971164-79af-4f53-cd42-bba7983be4f1"
      },
      "execution_count": 204,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[SystemMessage(content='Translate the following from English into Italian', additional_kwargs={}, response_metadata={}),\n",
              " HumanMessage(content='hi!', additional_kwargs={}, response_metadata={})]"
            ]
          },
          "metadata": {},
          "execution_count": 204
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = model.invoke(prompt)\n",
        "# print(response)\n",
        "print(response.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NUeIPLNp2Y89",
        "outputId": "1756fb52-9cfc-4b0d-dc2c-35792fbb911c"
      },
      "execution_count": 205,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ciao!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#ChatPromptTemplates\n"
      ],
      "metadata": {
        "id": "rZMoZOyAEyvL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "#defining prompt template\n",
        "prompt_template = ChatPromptTemplate([\n",
        "    (\"system\", \"You are a helpful assistant\"),\n",
        "    (\"user\", \"Tell me a joke about {topic}\")\n",
        "])\n",
        "#Give the template a topic\n",
        "prompt_value = prompt_template.invoke({\"topic\": \"cats\"})\n",
        "response=model.invoke(prompt)\n",
        "# print(response)\n",
        "print(response.content)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VSBjzuE0Eqpg",
        "outputId": "366f52ad-cab5-4b7b-c0d3-e88f26779059"
      },
      "execution_count": 206,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ciao!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ChatPrompt Templates\n"
      ],
      "metadata": {
        "id": "0zgM032fjeKG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "template = ChatPromptTemplate([\n",
        "    (\"system\", \"You are a helpful AI bot. Your name is {name}.\"),\n",
        "    (\"human\", \"Hello, how are you doing?\"),\n",
        "    (\"human\", \"{user_input}\"),\n",
        "    (\"human\",\"Tell me something about yourself\")  #helps it respond\n",
        "])\n",
        "\n",
        "prompt_value = template.invoke(\n",
        "    {\n",
        "        \"name\": \"Bob\",\n",
        "        \"user_input\": \"What is your name?\"\n",
        "    }\n",
        ")\n",
        "\n",
        "#If not passed to a model the template invoked will return a list of input template response\n"
      ],
      "metadata": {
        "id": "gd0FzYTVjjeI"
      },
      "execution_count": 207,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Model Response\n",
        "\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "\n",
        "response = model.invoke(prompt_value)\n",
        "print(response.content)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bZeb6ZckA3KG",
        "outputId": "fa51d692-3974-476a-c096-0c3057568d85"
      },
      "execution_count": 208,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello! My name is Bob. I'm an AI assistant designed to help answer questions, provide information, and assist with a variety of tasks. I can help with topics ranging from general knowledge to specific advice. How can I assist you today?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "RunnableParallel and Runnable concepts"
      ],
      "metadata": {
        "id": "q7P3emd0kyot"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://python.langchain.com/api_reference/core/runnables/langchain_core.runnables.base.RunnableParallel.html\n",
        "\n",
        "https://python.langchain.com/docs/concepts/runnables/"
      ],
      "metadata": {
        "id": "9OlckcAdkxG5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Standard Core Method Simple example\n",
        "\n",
        "from langchain_core.runnables import RunnableLambda\n",
        "\n",
        "def add_one(x: int) -> int:\n",
        "    return x + 1\n",
        "\n",
        "def mul_two(x):\n",
        "  return x * 2\n",
        "\n",
        "runnable_1 = RunnableLambda(add_one)\n",
        "runnable_2 = RunnableLambda(mul_two)\n",
        "chain = runnable_1 | runnable_2\n",
        "\n",
        "\n",
        "\"\"\"for single\n",
        "sequence.invoke(1)\n",
        "await sequence.ainvoke(1)\"\"\"\n",
        "\n",
        "#concurrent run\n",
        "chain.batch([1, 2, 3])\n",
        "await chain.abatch([1, 2, 3])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mi4YJB9TmBVv",
        "outputId": "90b3f6a4-3797-41fc-ac5c-eeaaed7c62c9"
      },
      "execution_count": 209,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[4, 6, 8]"
            ]
          },
          "metadata": {},
          "execution_count": 209
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Simple Runnable\n",
        "\n",
        "\n",
        "from langchain_core.runnables import RunnableLambda\n",
        "\n",
        "\"\"\"A RunnableSequence constructed using the `|` operator\"\"\"\n",
        "#Using lambda function\n",
        "\n",
        "sequence = RunnableLambda(lambda x: x + 1) | RunnableLambda(lambda x: x * 2)\n",
        "sequence.invoke(1)            # Output : 4\n",
        "sequence.batch([1, 2, 3])     # Ouptut : [4, 6, 8]\n",
        "\n",
        "\n",
        "\"\"\"A sequence that contains a RunnableParallel constructed using a dict literal\"\"\"\n",
        "sequence = RunnableLambda(lambda x: x + 1) | {\n",
        "    'mul_2': RunnableLambda(lambda x: x * 2),\n",
        "    'mul_5': RunnableLambda(lambda x: x * 5)\n",
        "}\n",
        "sequence.invoke(1) # {'mul_2': 4, 'mul_5': 10}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FEBYpVdWjoYu",
        "outputId": "94891fc4-7275-49b8-edbd-c701b3590599"
      },
      "execution_count": 210,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'mul_2': 4, 'mul_5': 10}"
            ]
          },
          "metadata": {},
          "execution_count": 210
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "NUJA9_LGo5RK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Runnable Parrallel  --> singular input run concurrently to multiple functions\n",
        "\n",
        "from langchain_core.runnables import RunnableLambda\n",
        "from langchain_core.runnables import RunnableParallel\n",
        "\n",
        "# chain = RunnableLambda(lambda x : x + 1) | RunnableLambda(lambda x : x * 2 ) | RunnableLambda(lambda x : x * 3)\n",
        "\n",
        "# chain = chain = RunnableParallel(lambda x : x + 1,lambda x : x * 2 ,lambda x : x * 3)\n",
        "# chain.invoke(1)\n",
        "\n",
        "def add_one(x: int) -> int:\n",
        "    return x + 1\n",
        "\n",
        "def mul_two(x: int) -> int:\n",
        "    return x * 2\n",
        "\n",
        "def mul_three(x: int) -> int:\n",
        "    return x * 3\n",
        "\n",
        "runnable_1 = RunnableLambda(add_one)\n",
        "runnable_2 = RunnableLambda(mul_two)\n",
        "runnable_3 = RunnableLambda(mul_three)\n",
        "\n",
        "\"\"\"Incorrect as RunnableParallel expects a dictionary, not positional arguments.\n",
        "You must pass a dictionary where each key is a label for the function, and the\n",
        "value is the Runnable.\"\"\"\n",
        "# sequence = RunnableParallel(runnable_1, runnable_2, runnable_3)\n",
        "\n",
        "sequence =RunnableParallel(add_1=runnable_1,mul_2=runnable_2,mul_3=runnable_3)\n",
        "\n",
        "sequence.invoke(1)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IbYmDNSjqhl5",
        "outputId": "95122471-a5df-400e-eff7-dd800f17d379"
      },
      "execution_count": 211,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'add_1': 2, 'mul_2': 2, 'mul_3': 3}"
            ]
          },
          "metadata": {},
          "execution_count": 211
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#OUTPUT PARSERS -\n",
        "  Output parser is responsible for taking the output of a model and transforming it to a more suitable format for downstream tasks. Useful when you are using LLMs to generate structured data, or to normalize output from chat models and LLMs."
      ],
      "metadata": {
        "id": "uhCKQpD9pwYW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://python.langchain.com/docs/concepts/output_parsers/"
      ],
      "metadata": {
        "id": "UhijP20ptphz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#NOTE (JSON outpur parsers)\n",
        "JsonOutputParser implements the standard Runnable Interface"
      ],
      "metadata": {
        "id": "VCpfgdCxutis"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#  \"\"\" Example by ----->Prabesh Dai\"\"\"\n",
        "\n",
        "\n",
        "# # from langchain_core.output_parsers.json import SimpleJsonOutputParser\n",
        "# # from langchain_openai import ChatOpenAI\n",
        "# # from langchain.prompts import PromptTemplate\n",
        "\n",
        "# # prompt = PromptTemplate.from_template(\"Extract relavant information about what user is asking for in the {query}.What is the topic of the question.What is the action the user is trying to ask.Give me answer in json format with keys topic and action\")\n",
        "\n",
        "# # chain = prompt | model | SimpleJsonOutputParser()\n",
        "# # outputs=10\n",
        "# # topic=\"Prepare slides about software engineering\"\n",
        "# # chain.invoke({\"query\":topic,\"outputs\":outputs})\n",
        "\n",
        "\n",
        "# \"\"\"Improved version\"\"\"\n",
        "\n",
        "# from langchain_core.output_parsers.json import SimpleJsonOutputParser\n",
        "# from langchain_openai import ChatOpenAI\n",
        "# from langchain.prompts import PromptTemplate\n",
        "\n",
        "# # Create a prompt template that takes 'query' as a variable\n",
        "# prompt = PromptTemplate.from_template(\n",
        "#     \"Extract relevant information about what user is asking for in the query: {query}. \"\n",
        "#     \"What is the topic of the input by the user and  What action is the user trying to? \"\n",
        "#     \"Give the answer in JSON format with keys 'topic' and 'action'.\"\n",
        "# )\n",
        "\n",
        "# # Initialize the model (DONE ABOVE)\n",
        "\n",
        "\n",
        "# # Create the chain: prompt -> model -> JSON parser\n",
        "# chain = prompt | model | SimpleJsonOutputParser()\n",
        "\n",
        "# # Define the input\n",
        "# input_text = \"Prepare slides about software engineering\"\n",
        "\n",
        "# # Invoke the chain with the query\n",
        "# output = chain.invoke({\"query\": input_text})\n",
        "\n",
        "# # Print the result\n",
        "# print(output)\n",
        "\n"
      ],
      "metadata": {
        "id": "hmjFq3d78lZW"
      },
      "execution_count": 212,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Above example for combination of system template and prompt template\n",
        "\n",
        "system_template = \"Translate the following from English into {language}\"\n",
        "\n",
        "prompt_template = ChatPromptTemplate.from_messages(\n",
        "    [(\"system\", system_template), (\"user\", \"{text}\")]\n",
        ")\n",
        "\n",
        "prompt = prompt_template.invoke({\"language\": \"Italian\", \"text\": \"hi!\"})\n",
        "\n",
        "response = model.invoke(prompt)\n",
        "# print(response)\n",
        "print(response.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sFNCqCR4njBx",
        "outputId": "e2bb6ecd-35e2-4105-a6a4-e4b4eaa4bd56"
      },
      "execution_count": 213,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ciao!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#NOTE (Later)\n",
        "*   prompt-input_variables\n",
        "*   ResponseSchema in langchainOutputParsers\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "r8FabQ-F9Zzn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#PREPARATION OF SLIDES\n",
        "\n",
        "#CHAINING\n"
      ],
      "metadata": {
        "id": "s8aPzzUDrWff"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from langchain_core.prompts import ChatPromptTemplate\n",
        "# from langchain_core.output_parsers.json import SimpleJsonOutputParser\n",
        "# from langchain_openai import ChatOpenAI\n",
        "\n",
        "\n",
        "# # Prompt template creation\n",
        "# system_template = \"You are an intelligent assistant that extracts structured information.\"\n",
        "# user_template = (\n",
        "#     \"Given the user's input: '{query}', extract:\\n\"\n",
        "#     \"- topic: what the input is about\\n\"\n",
        "#     \"- action: what the user wants to do \\n\"\n",
        "#     \" - information: what information do they want about the input \\n\"\n",
        "#     \"Return the result in JSON with keys 'topic', 'action' and 'information'.\"\n",
        "# )\n",
        "\n",
        "# # Combine into a chatPrompt\n",
        "# prompt_template = ChatPromptTemplate.from_messages([(\"system\", system_template),(\"user\", user_template),])\n",
        "\n",
        "# # Model Initializaion\n",
        "# \"\"\"Already set up above as   ----> model = init_chat_model(\"gpt-4o-mini\", model_provider=\"openai\",api_key=openai_api_key)\"\"\"\n",
        "\n",
        "\n",
        "# # JSON parser sett\n",
        "# parser = SimpleJsonOutputParser()\n",
        "\n",
        "\n",
        "# chain = prompt_template | model | parser\n",
        "\n",
        "\n",
        "\n",
        "# #Input by the user (Redinfe as required)\n",
        "# # query_text = \"Prepare slides about software engineering\"\n",
        "\n",
        "# query_text = \"Provide me with slide about Rana Regime in Nepal\"\n",
        "\n",
        "\n",
        "# # chain\n",
        "# output = chain.invoke({\"query\": query_text})\n",
        "\n",
        "\n",
        "# print(output)\n",
        "\n"
      ],
      "metadata": {
        "id": "0g9OZ1vS6Fzf"
      },
      "execution_count": 214,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade --quiet  wikipedia"
      ],
      "metadata": {
        "id": "t2fivPLJXmJc"
      },
      "execution_count": 215,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain_community"
      ],
      "metadata": {
        "id": "12H1r2XJh35W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8420818-494d-44a1-8ac6-3ce830475b96"
      },
      "execution_count": 216,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain_community in /usr/local/lib/python3.11/dist-packages (0.3.25)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.65 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.3.65)\n",
            "Requirement already satisfied: langchain<1.0.0,>=0.3.25 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.3.25)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (2.0.41)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (3.11.15)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (9.1.2)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.6.7)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (2.9.1)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.3.45)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.4.0)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (2.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.4.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.20.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.26.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.25->langchain_community) (0.3.8)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.25->langchain_community) (2.11.5)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.65->langchain_community) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.65->langchain_community) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.65->langchain_community) (4.14.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain_community) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain_community) (3.10.18)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain_community) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain_community) (0.23.0)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain_community) (1.1.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain_community) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community) (2025.4.26)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.2.2)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.65->langchain_community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.25->langchain_community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.25->langchain_community) (2.33.2)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.1.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community) (1.3.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.tools import WikipediaQueryRun      # imports the tool wrapper that allows you to use Wikipedia like a function/tool inside a LangChain agent or pipeline\n",
        "from langchain_community.utilities import WikipediaAPIWrapper   # handles actual API interaction with Wikipedia"
      ],
      "metadata": {
        "id": "sMqWthJ9sMjv"
      },
      "execution_count": 217,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wikipedia = WikipediaQueryRun(api_wrapper=WikipediaAPIWrapper())"
      ],
      "metadata": {
        "id": "r_qLWF2AuQW2"
      },
      "execution_count": 218,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# wiki_result = wikipedia.run(output[\"topic\"])\n",
        "# print(wiki_result)"
      ],
      "metadata": {
        "id": "ObVM3WT8ui13"
      },
      "execution_count": 219,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install --upgrade --quiet langchain-community"
      ],
      "metadata": {
        "id": "sDVtPEREzaWd"
      },
      "execution_count": 220,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from langchain_community.tools import BraveSearch\n",
        "# tool = BraveSearch.from_api_key(api_key=OPENAI_API_KEY)"
      ],
      "metadata": {
        "id": "nbGhIoc1gJL2"
      },
      "execution_count": 221,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "New |\n",
        "\n",
        "> Different t\n",
        "\n"
      ],
      "metadata": {
        "id": "AAVwza2QvFH1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "system_template = \"You are an intelligent assistant that extracts structured information.\"\n",
        "user_template = (\n",
        "    \"Given the user's input: '{query}', extract:\\n\"\n",
        "     \"- topic: the subject of the presentation\\n\"\n",
        "     \"- action: what the user wants to do\\n\"\n",
        "     \"- information: if no specific information is requested, infer details\\n\"\n",
        "     \"- slides: number of slides if mentioned (default to 7 if not)\\n\"\n",
        "     \"Return JSON with keys: topic, action, information, slides.\"\n",
        ")\n",
        "\n",
        "extraction_prompt = ChatPromptTemplate.from_messages([(\"system\", system_template),(\"user\", user_template)])\n",
        "\n",
        "extraction_parser = SimpleJsonOutputParser()\n",
        "extraction_chain = extraction_prompt | model | extraction_parser\n"
      ],
      "metadata": {
        "id": "5ZL9VBuEyPZW"
      },
      "execution_count": 230,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wikipedia = WikipediaQueryRun(api_wrapper=WikipediaAPIWrapper())"
      ],
      "metadata": {
        "id": "5TO7bEf3z6rB"
      },
      "execution_count": 223,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "parallel_chain = RunnableParallel({\n",
        "    \"parsed\": extraction_chain,\n",
        "    \"original_query\": lambda x: x[\"query\"]\n",
        "}) | RunnableLambda(lambda x: {\n",
        "    \"topic\": x[\"parsed\"][\"topic\"],\n",
        "    \"action\": x[\"parsed\"][\"action\"],\n",
        "    \"information\": x[\"parsed\"][\"information\"],\n",
        "    \"slides\": int(x[\"parsed\"].get(\"slides\", 7)),\n",
        "    \"wiki_content\": wikipedia.run(x[\"parsed\"][\"topic\"])\n",
        "})"
      ],
      "metadata": {
        "id": "etx8Iqn1gSxd"
      },
      "execution_count": 224,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "slide_prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\",\n",
        "     \"You are a helpful assistant that formats information into a slide show.\"),\n",
        "    (\"user\",\n",
        "     \"Using the following content from Wikipedia:\\n\\n\"\n",
        "     \"{wiki_content}\\n\\n\"\n",
        "     \"Create a slide show on the topic '{topic}'.\\n\"\n",
        "     \"Generate exactly {slides} slides.\\n\"\n",
        "     \"Each slide should:\\n\"\n",
        "     \"- Be unique (no repeated info)\\n\"\n",
        "     \"- Have clear, concise content\\n\"\n",
        "    #  \"- Be limited to key points (3-5 per slide max)\\n\"\n",
        "     \"- Limit the information in the slide in about 70 words or 5 to 7 key points if given in points \\n\"\n",
        "     \"- use alternatives of paragraphs and points in the slides randomly based of the derivation of information\"\n",
        "     \"Return the slide data as a numbered list, like:\\n\"\n",
        "     \"Slide 1: ...\\n\"\n",
        "     \"Slide 2: ...\\n\")\n",
        "])"
      ],
      "metadata": {
        "id": "wXQBDsm10uU8"
      },
      "execution_count": 238,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "final_chain = parallel_chain | slide_prompt | model\n",
        "\n",
        "# 📌 7. Run on example input\n",
        "user_input = {\"query\": \"Prepare the slides about Rana Regime in Nepal\"}\n",
        "slide_output = final_chain.invoke(user_input)\n",
        "\n",
        "print(slide_output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VArcp9XFugKe",
        "outputId": "9abcce57-2bb5-4eee-d0f7-d4aea4a32807"
      },
      "execution_count": 239,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "content=\"Here is the slide show on the topic 'Rana Regime in Nepal':\\n\\nSlide 1:  \\n**Title: Overview of the Rana Dynasty**  \\n- Ruled Nepal from 1846 to 1951  \\n- Imposed authoritarianism, reducing Shah monarch to figurehead  \\n- Positions of power became hereditary among the Ranas  \\n- Descended from the Kunwar family of the Gorkha Kingdom  \\n- Notable for their iron-fisted governance  \\n\\nSlide 2:  \\n**Title: Political Dynamics under Rana Rule**  \\nThe Rana dynasty established a political system that concentrated power among a small elite.  \\n- The monarchy was sidelined, with King Tribhuvan reduced to a symbolic role.  \\n- Lasted for 104 years.  \\n- Contributed to widespread dissatisfaction, leading to the revolution of 1951.  \\n\\nSlide 3:  \\n**Title: The 1951 Nepalese Revolution**  \\n- Also known as Sat Salko Kranti  \\n- A political movement against Rana rule  \\n- Marked the end of over a century of authoritarian governance  \\n- Resulted in the restoration of power to the monarchy  \\n- Led to the drafting of a new constitution for Nepal  \\n\\nSlide 4:  \\n**Title: Founding of the Communist Party of Nepal**  \\n- Established on September 15, 1949  \\n- Aimed to oppose the autocratic Rana regime, feudalism, and imperialism  \\n- Key founding figures included Pushpa Lal Shrestha and Niranjan Govinda Vaidya  \\n- Played a significant role in mobilizing support against the Ranas  \\n\\nSlide 5:  \\n**Title: Key Figures in the Rana Dynasty**  \\n- **King Tribhuvan**: Symbol of the monarchy during Rana rule  \\n- **Rana Leaders**: Prime Ministers were hereditary, maintaining power within the family  \\n- Notable Ranas included Bhim Shamsher JBR and Juddha Shamsher JBR  \\n- Strong influence on the political landscape of Nepal  \\n\\nSlide 6:  \\n**Title: Consequences of the Rana Rule**  \\n- Significant impact on Nepal's political structure and governance  \\n- Deepened public grievances leading to calls for reform  \\n- Set the stage for the political movements of the 1950s and beyond  \\n- Initiated the transition towards a democratic framework  \\n\\nSlide 7:  \\n**Title: Legacy of the Rana Regime**  \\n- Historical significance in shaping modern Nepali politics  \\n- The end of the Rana dynasty marked a shift towards constitutional monarchy  \\n- Laid the groundwork for subsequent democratic developments  \\n- Continuing influence on Nepal's political parties and governance structures  \" additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 534, 'prompt_tokens': 587, 'total_tokens': 1121, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_34a54ae93c', 'id': 'chatcmpl-BiI4pW3zRdagVeGxMaht78ZzcOVpb', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='run--29338dcf-1a6e-4236-a09b-c1e94cac1452-0' usage_metadata={'input_tokens': 587, 'output_tokens': 534, 'total_tokens': 1121, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(slide_output.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z4coYOFIxswr",
        "outputId": "4c958bf0-3082-4d56-e8cf-63ac121007a2"
      },
      "execution_count": 240,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Here is the slide show on the topic 'Rana Regime in Nepal':\n",
            "\n",
            "Slide 1:  \n",
            "**Title: Overview of the Rana Dynasty**  \n",
            "- Ruled Nepal from 1846 to 1951  \n",
            "- Imposed authoritarianism, reducing Shah monarch to figurehead  \n",
            "- Positions of power became hereditary among the Ranas  \n",
            "- Descended from the Kunwar family of the Gorkha Kingdom  \n",
            "- Notable for their iron-fisted governance  \n",
            "\n",
            "Slide 2:  \n",
            "**Title: Political Dynamics under Rana Rule**  \n",
            "The Rana dynasty established a political system that concentrated power among a small elite.  \n",
            "- The monarchy was sidelined, with King Tribhuvan reduced to a symbolic role.  \n",
            "- Lasted for 104 years.  \n",
            "- Contributed to widespread dissatisfaction, leading to the revolution of 1951.  \n",
            "\n",
            "Slide 3:  \n",
            "**Title: The 1951 Nepalese Revolution**  \n",
            "- Also known as Sat Salko Kranti  \n",
            "- A political movement against Rana rule  \n",
            "- Marked the end of over a century of authoritarian governance  \n",
            "- Resulted in the restoration of power to the monarchy  \n",
            "- Led to the drafting of a new constitution for Nepal  \n",
            "\n",
            "Slide 4:  \n",
            "**Title: Founding of the Communist Party of Nepal**  \n",
            "- Established on September 15, 1949  \n",
            "- Aimed to oppose the autocratic Rana regime, feudalism, and imperialism  \n",
            "- Key founding figures included Pushpa Lal Shrestha and Niranjan Govinda Vaidya  \n",
            "- Played a significant role in mobilizing support against the Ranas  \n",
            "\n",
            "Slide 5:  \n",
            "**Title: Key Figures in the Rana Dynasty**  \n",
            "- **King Tribhuvan**: Symbol of the monarchy during Rana rule  \n",
            "- **Rana Leaders**: Prime Ministers were hereditary, maintaining power within the family  \n",
            "- Notable Ranas included Bhim Shamsher JBR and Juddha Shamsher JBR  \n",
            "- Strong influence on the political landscape of Nepal  \n",
            "\n",
            "Slide 6:  \n",
            "**Title: Consequences of the Rana Rule**  \n",
            "- Significant impact on Nepal's political structure and governance  \n",
            "- Deepened public grievances leading to calls for reform  \n",
            "- Set the stage for the political movements of the 1950s and beyond  \n",
            "- Initiated the transition towards a democratic framework  \n",
            "\n",
            "Slide 7:  \n",
            "**Title: Legacy of the Rana Regime**  \n",
            "- Historical significance in shaping modern Nepali politics  \n",
            "- The end of the Rana dynasty marked a shift towards constitutional monarchy  \n",
            "- Laid the groundwork for subsequent democratic developments  \n",
            "- Continuing influence on Nepal's political parties and governance structures  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "udvbc5sZ5Fz0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}